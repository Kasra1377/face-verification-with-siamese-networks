{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"utils.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1cWUQpPgnsB0cyYqGtXV1GxaU_wuc2Eja","authorship_tag":"ABX9TyPm5V9aDHgubJt2wc9U98We"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"8C1UHqKC90PF","executionInfo":{"status":"ok","timestamp":1632052238282,"user_tz":-270,"elapsed":374,"user":{"displayName":"Kasra Sadeghianpoor","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-M-IQfCdV1sDtftP0aqLtsS4eCJ8Pzr5Ka4Ee=s64","userId":"12889102283785354184"}}},"source":["# %cd \"/content/drive/MyDrive/My Projects/face-verification-with-siamese-network\""],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"U1DrZnlF91F6","executionInfo":{"status":"ok","timestamp":1632052238701,"user_tz":-270,"elapsed":9,"user":{"displayName":"Kasra Sadeghianpoor","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-M-IQfCdV1sDtftP0aqLtsS4eCJ8Pzr5Ka4Ee=s64","userId":"12889102283785354184"}}},"source":["# !pip install import-ipynb"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"RxsdkUXbZ-Br","executionInfo":{"status":"ok","timestamp":1632052240972,"user_tz":-270,"elapsed":2278,"user":{"displayName":"Kasra Sadeghianpoor","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-M-IQfCdV1sDtftP0aqLtsS4eCJ8Pzr5Ka4Ee=s64","userId":"12889102283785354184"}}},"source":["# import import_ipynb\n","# import config\n","\n","from keras.callbacks import LearningRateScheduler\n","import tensorflow.keras.backend as K\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import numpy as np"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"JsEFeTYnaG2g","executionInfo":{"status":"ok","timestamp":1632052240976,"user_tz":-270,"elapsed":15,"user":{"displayName":"Kasra Sadeghianpoor","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-M-IQfCdV1sDtftP0aqLtsS4eCJ8Pzr5Ka4Ee=s64","userId":"12889102283785354184"}}},"source":["def make_pairs(images , labels):\n","  # initialize the pairImages and pairLabels list so we can save \n","  # the pair images in former list and save the corresponding label\n","  # into the latter list\n","  pairImages = []\n","  pairLabels = []\n","\n","  # get the number of unique calsses in the dataset\n","  numClasses = len(np.unique(labels))\n","  \n","  # build a list that represents the indeces of each label \n","  # in the dataset\n","  idx = [np.where(labels == i)[0] for i in range(0 , numClasses)]\n","\n","  # loop over all the images\n","  for idxA in range(len(images)):\n","    # grab the corresponding image and label\n","    currentImage = images[idxA]\n","    label = labels[idxA]\n","\n","    # pick an image that has the same label as\n","    # privious image\n","    idxB = np.random.choice(idx[label])\n","    posImage = images[idxB]\n","\n","    pairImages.append([currentImage, posImage])\n","    pairLabels.append([1])\n","\n","    # select specific indeces that have a different label as the \n","    # current label. Then select a random index from these specific\n","    # indeces and grab the corresponding image.\n","    negIdx = np.where(labels != label)[0]\n","    negImage = images[np.random.choice(negIdx)]\n","\n","    pairImages.append([currentImage, negImage])\n","    pairLabels.append([0])\n","\n","  return (np.array(pairImages), np.array(pairLabels))"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vm8skM7waKHt","executionInfo":{"status":"ok","timestamp":1632052240977,"user_tz":-270,"elapsed":12,"user":{"displayName":"Kasra Sadeghianpoor","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-M-IQfCdV1sDtftP0aqLtsS4eCJ8Pzr5Ka4Ee=s64","userId":"12889102283785354184"}}},"source":["def euclidean_distance(vectors):\n","  (featsA, featsB) = vectors\n","\n","  sumSquared = K.sum(K.square(featsA - featsB) , axis = 1 , keepdims=True)\n","\n","  return K.sqrt(K.maximum(sumSquared , K.epsilon()))"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"OdL6zggIaN8-","executionInfo":{"status":"ok","timestamp":1632052240978,"user_tz":-270,"elapsed":12,"user":{"displayName":"Kasra Sadeghianpoor","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-M-IQfCdV1sDtftP0aqLtsS4eCJ8Pzr5Ka4Ee=s64","userId":"12889102283785354184"}}},"source":["def plot_training(H, plotPath):\n","\t# construct a plot that plots and saves the training history\n","\tplt.style.use(\"ggplot\")\n","\tplt.figure()\n","\tplt.plot(H.history[\"loss\"], label=\"train_loss\")\n","\tplt.plot(H.history[\"val_loss\"], label=\"val_loss\")\n","\tplt.title(\"Contrastive Loss\")\n","\tplt.xlabel(\"Epoch #\")\n","\tplt.ylabel(\"Loss/Accuracy\")\n","\tplt.legend(loc=\"lower left\")\n","\tplt.savefig(plotPath)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"GS4G0Om9aSwM","executionInfo":{"status":"ok","timestamp":1632052240978,"user_tz":-270,"elapsed":11,"user":{"displayName":"Kasra Sadeghianpoor","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-M-IQfCdV1sDtftP0aqLtsS4eCJ8Pzr5Ka4Ee=s64","userId":"12889102283785354184"}}},"source":["def contrastive_loss(y, preds , margin=1):\n","  # cast the ground truth value dtype into prediction\n","  # value datatype to have the same datatype. in order to\n","  # able to do some calculations between y and preds\n","  y = tf.cast(y , preds.dtype)\n","\n","  # calcualte the contrastive loss function via\n","  # tensorflow backend API\n","  squaredPreds = K.square(preds)\n","  squaredMargin = K.square(K.maximum(margin - preds , 0))\n","  loss = K.mean(y * squaredPreds + (1 - y) * squaredMargin)\n","\n","  # return the computed contrastive loss\n","  return loss"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"PZpi-u4F6_2K","executionInfo":{"status":"ok","timestamp":1632052240979,"user_tz":-270,"elapsed":11,"user":{"displayName":"Kasra Sadeghianpoor","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-M-IQfCdV1sDtftP0aqLtsS4eCJ8Pzr5Ka4Ee=s64","userId":"12889102283785354184"}}},"source":["class learning_rate_schedule():\n","  def plot(self, epochs, title=\"Learning Rate Schedule\"):\n","    lrs = [self(i) for i in epochs]\n","    plt.style.use(\"ggplot\")\n","    plt.figure()\n","    plt.plot(epochs, lrs)\n","    plt.title(title)\n","    plt.xlabel(\"Epoch #\")\n","    plt.ylabel(\"Learning Rate\")\n","    plt.show()\n","\n","class step_decay(learning_rate_schedule):\n","  def __init__(self, initAlpha = 0.001 , factor = 0.25 , dropEvery = 10):\n","    self.initAlpha = initAlpha\n","    self.factor = factor\n","    self.dropEvery = dropEvery\n","\n","  def __call__(self, epoch):\n","    # compute the learning rate for the current epoch\n","    exp = np.floor((1 + epoch) / self.dropEvery)\n","    alpha = self.initAlpha * (self.factor ** exp)\n","    # return the learning rate\n","    return float(alpha)\n","\n","class polynomial_decay(learning_rate_schedule):\n","\tdef __init__(self, maxEpochs=20, initAlpha=0.001, power=1.0):\n","\t\t# store the maximum number of epochs, base learning rate,\n","\t\t# and power of the polynomial\n","\t\tself.maxEpochs = maxEpochs\n","\t\tself.initAlpha = initAlpha\n","\t\tself.power = power\n","\tdef __call__(self, epoch):\n","\t\t# compute the new learning rate based on polynomial decay\n","\t\tdecay = (1 - (epoch / float(self.maxEpochs))) ** self.power\n","\t\talpha = self.initAlpha * decay\n","\t\t# return the new learning rate\n","\t\treturn float(alpha)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"ikS6xukp8AH5","executionInfo":{"status":"ok","timestamp":1632052240981,"user_tz":-270,"elapsed":12,"user":{"displayName":"Kasra Sadeghianpoor","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-M-IQfCdV1sDtftP0aqLtsS4eCJ8Pzr5Ka4Ee=s64","userId":"12889102283785354184"}}},"source":["schedule = \"step_decay\"\n","\n","if schedule == \"linear\":\n","  schedule = polynomial_decay(maxEpochs = 100 , initAlpha = 1e-3 , power = 1.0)\n","\n","if schedule == \"polynomial\":\n","  schedule = polynomial_decay(maxEpochs = 100 , initAlpha =1e-3 , power = 3.0)\n","\n","if schedule == \"step_decay\":\n","  schedule = step_decay(initAlpha = 1e-3 , factor = 0.25 , dropEvery = 20)\n","\n","lrate = LearningRateScheduler(schedule)"],"execution_count":9,"outputs":[]}]}